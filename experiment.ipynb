{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch Data from CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy\n",
      "  Using cached numpy-1.24.4-cp38-cp38-win_amd64.whl (14.9 MB)\n",
      "Collecting pandas\n",
      "  Downloading pandas-2.0.3-cp38-cp38-win_amd64.whl (10.8 MB)\n",
      "                                              0.0/10.8 MB ? eta -:--:--\n",
      "                                              0.1/10.8 MB 1.1 MB/s eta 0:00:10\n",
      "                                              0.2/10.8 MB 1.4 MB/s eta 0:00:08\n",
      "                                              0.2/10.8 MB 1.5 MB/s eta 0:00:07\n",
      "     -                                        0.3/10.8 MB 1.6 MB/s eta 0:00:07\n",
      "     -                                        0.4/10.8 MB 1.5 MB/s eta 0:00:07\n",
      "     -                                        0.5/10.8 MB 1.6 MB/s eta 0:00:07\n",
      "     --                                       0.6/10.8 MB 1.6 MB/s eta 0:00:07\n",
      "     --                                       0.6/10.8 MB 1.5 MB/s eta 0:00:07\n",
      "     --                                       0.7/10.8 MB 1.6 MB/s eta 0:00:07\n",
      "     --                                       0.8/10.8 MB 1.6 MB/s eta 0:00:07\n",
      "     ---                                      0.9/10.8 MB 1.6 MB/s eta 0:00:07\n",
      "     ---                                      0.9/10.8 MB 1.6 MB/s eta 0:00:07\n",
      "     ---                                      1.0/10.8 MB 1.6 MB/s eta 0:00:07\n",
      "     ----                                     1.1/10.8 MB 1.6 MB/s eta 0:00:06\n",
      "     ----                                     1.2/10.8 MB 1.6 MB/s eta 0:00:07\n",
      "     ----                                     1.3/10.8 MB 1.6 MB/s eta 0:00:06\n",
      "     ----                                     1.3/10.8 MB 1.6 MB/s eta 0:00:06\n",
      "     -----                                    1.4/10.8 MB 1.6 MB/s eta 0:00:06\n",
      "     -----                                    1.5/10.8 MB 1.6 MB/s eta 0:00:06\n",
      "     -----                                    1.6/10.8 MB 1.6 MB/s eta 0:00:06\n",
      "     ------                                   1.6/10.8 MB 1.6 MB/s eta 0:00:06\n",
      "     ------                                   1.7/10.8 MB 1.6 MB/s eta 0:00:06\n",
      "     ------                                   1.8/10.8 MB 1.6 MB/s eta 0:00:06\n",
      "     ------                                   1.8/10.8 MB 1.6 MB/s eta 0:00:06\n",
      "     -------                                  2.0/10.8 MB 1.6 MB/s eta 0:00:06\n",
      "     -------                                  2.0/10.8 MB 1.6 MB/s eta 0:00:06\n",
      "     -------                                  2.1/10.8 MB 1.6 MB/s eta 0:00:06\n",
      "     --------                                 2.2/10.8 MB 1.6 MB/s eta 0:00:06\n",
      "     --------                                 2.3/10.8 MB 1.6 MB/s eta 0:00:06\n",
      "     --------                                 2.4/10.8 MB 1.6 MB/s eta 0:00:06\n",
      "     ---------                                2.5/10.8 MB 1.6 MB/s eta 0:00:06\n",
      "     ---------                                2.5/10.8 MB 1.6 MB/s eta 0:00:06\n",
      "     ---------                                2.6/10.8 MB 1.6 MB/s eta 0:00:06\n",
      "     ---------                                2.7/10.8 MB 1.6 MB/s eta 0:00:06\n",
      "     ----------                               2.7/10.8 MB 1.6 MB/s eta 0:00:06\n",
      "     ----------                               2.8/10.8 MB 1.6 MB/s eta 0:00:06\n",
      "     ----------                               2.8/10.8 MB 1.5 MB/s eta 0:00:06\n",
      "     ----------                               2.9/10.8 MB 1.5 MB/s eta 0:00:06\n",
      "     -----------                              3.0/10.8 MB 1.5 MB/s eta 0:00:06\n",
      "     -----------                              3.0/10.8 MB 1.5 MB/s eta 0:00:06\n",
      "     -----------                              3.1/10.8 MB 1.5 MB/s eta 0:00:06\n",
      "     -----------                              3.2/10.8 MB 1.5 MB/s eta 0:00:06\n",
      "     ------------                             3.3/10.8 MB 1.5 MB/s eta 0:00:05\n",
      "     ------------                             3.3/10.8 MB 1.5 MB/s eta 0:00:05\n",
      "     ------------                             3.4/10.8 MB 1.5 MB/s eta 0:00:05\n",
      "     ------------                             3.5/10.8 MB 1.5 MB/s eta 0:00:05\n",
      "     -------------                            3.6/10.8 MB 1.5 MB/s eta 0:00:05\n",
      "     -------------                            3.7/10.8 MB 1.5 MB/s eta 0:00:05\n",
      "     -------------                            3.7/10.8 MB 1.5 MB/s eta 0:00:05\n",
      "     --------------                           3.8/10.8 MB 1.5 MB/s eta 0:00:05\n",
      "     --------------                           3.9/10.8 MB 1.5 MB/s eta 0:00:05\n",
      "     --------------                           4.0/10.8 MB 1.5 MB/s eta 0:00:05\n",
      "     ---------------                          4.1/10.8 MB 1.4 MB/s eta 0:00:05\n",
      "     ---------------                          4.1/10.8 MB 1.4 MB/s eta 0:00:05\n",
      "     ---------------                          4.2/10.8 MB 1.4 MB/s eta 0:00:05\n",
      "     ---------------                          4.2/10.8 MB 1.4 MB/s eta 0:00:05\n",
      "     ----------------                         4.4/10.8 MB 1.5 MB/s eta 0:00:05\n",
      "     ----------------                         4.5/10.8 MB 1.5 MB/s eta 0:00:05\n",
      "     -----------------                        4.6/10.8 MB 1.5 MB/s eta 0:00:05\n",
      "     -----------------                        4.7/10.8 MB 1.5 MB/s eta 0:00:05\n",
      "     -----------------                        4.8/10.8 MB 1.5 MB/s eta 0:00:04\n",
      "     ------------------                       5.0/10.8 MB 1.5 MB/s eta 0:00:04\n",
      "     ------------------                       5.1/10.8 MB 1.6 MB/s eta 0:00:04\n",
      "     -------------------                      5.2/10.8 MB 1.6 MB/s eta 0:00:04\n",
      "     -------------------                      5.3/10.8 MB 1.6 MB/s eta 0:00:04\n",
      "     --------------------                     5.5/10.8 MB 1.6 MB/s eta 0:00:04\n",
      "     --------------------                     5.7/10.8 MB 1.6 MB/s eta 0:00:04\n",
      "     ---------------------                    5.8/10.8 MB 1.6 MB/s eta 0:00:04\n",
      "     ---------------------                    5.9/10.8 MB 1.7 MB/s eta 0:00:03\n",
      "     ----------------------                   6.1/10.8 MB 1.7 MB/s eta 0:00:03\n",
      "     -----------------------                  6.2/10.8 MB 1.7 MB/s eta 0:00:03\n",
      "     -----------------------                  6.4/10.8 MB 1.7 MB/s eta 0:00:03\n",
      "     ------------------------                 6.5/10.8 MB 1.7 MB/s eta 0:00:03\n",
      "     ------------------------                 6.6/10.8 MB 1.7 MB/s eta 0:00:03\n",
      "     ------------------------                 6.7/10.8 MB 1.7 MB/s eta 0:00:03\n",
      "     -------------------------                6.9/10.8 MB 1.8 MB/s eta 0:00:03\n",
      "     -------------------------                7.0/10.8 MB 1.8 MB/s eta 0:00:03\n",
      "     --------------------------               7.1/10.8 MB 1.8 MB/s eta 0:00:03\n",
      "     --------------------------               7.2/10.8 MB 1.8 MB/s eta 0:00:03\n",
      "     ---------------------------              7.4/10.8 MB 1.8 MB/s eta 0:00:02\n",
      "     ---------------------------              7.5/10.8 MB 1.8 MB/s eta 0:00:02\n",
      "     ----------------------------             7.6/10.8 MB 1.8 MB/s eta 0:00:02\n",
      "     ----------------------------             7.7/10.8 MB 1.8 MB/s eta 0:00:02\n",
      "     -----------------------------            7.9/10.8 MB 1.8 MB/s eta 0:00:02\n",
      "     -----------------------------            8.0/10.8 MB 1.8 MB/s eta 0:00:02\n",
      "     ------------------------------           8.1/10.8 MB 1.9 MB/s eta 0:00:02\n",
      "     ------------------------------           8.3/10.8 MB 1.9 MB/s eta 0:00:02\n",
      "     -------------------------------          8.4/10.8 MB 1.9 MB/s eta 0:00:02\n",
      "     -------------------------------          8.6/10.8 MB 1.9 MB/s eta 0:00:02\n",
      "     --------------------------------         8.8/10.8 MB 1.9 MB/s eta 0:00:02\n",
      "     ---------------------------------        8.9/10.8 MB 1.9 MB/s eta 0:00:01\n",
      "     ---------------------------------        9.1/10.8 MB 1.9 MB/s eta 0:00:01\n",
      "     ----------------------------------       9.2/10.8 MB 2.0 MB/s eta 0:00:01\n",
      "     ----------------------------------       9.4/10.8 MB 2.0 MB/s eta 0:00:01\n",
      "     -----------------------------------      9.6/10.8 MB 2.0 MB/s eta 0:00:01\n",
      "     ------------------------------------     9.8/10.8 MB 2.0 MB/s eta 0:00:01\n",
      "     -------------------------------------    10.0/10.8 MB 2.0 MB/s eta 0:00:01\n",
      "     -------------------------------------    10.1/10.8 MB 2.0 MB/s eta 0:00:01\n",
      "     --------------------------------------   10.3/10.8 MB 2.1 MB/s eta 0:00:01\n",
      "     --------------------------------------   10.5/10.8 MB 2.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------  10.6/10.8 MB 2.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------  10.7/10.8 MB 2.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------  10.8/10.8 MB 2.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------  10.8/10.8 MB 2.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 10.8/10.8 MB 2.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\haikal\\appdata\\roaming\\python\\python38\\site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Downloading pytz-2024.1-py2.py3-none-any.whl (505 kB)\n",
      "                                              0.0/505.5 kB ? eta -:--:--\n",
      "     ---------------                        204.8/505.5 kB 6.3 MB/s eta 0:00:01\n",
      "     ------------------------------------   491.5/505.5 kB 4.4 MB/s eta 0:00:01\n",
      "     -------------------------------------- 505.5/505.5 kB 4.0 MB/s eta 0:00:00\n",
      "Collecting tzdata>=2022.1 (from pandas)\n",
      "  Downloading tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
      "                                              0.0/345.4 kB ? eta -:--:--\n",
      "     ------------------------               225.3/345.4 kB 4.6 MB/s eta 0:00:01\n",
      "     -------------------------------------- 345.4/345.4 kB 4.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\haikal\\appdata\\roaming\\python\\python38\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Installing collected packages: pytz, tzdata, numpy, pandas\n",
      "Successfully installed numpy-1.24.4 pandas-2.0.3 pytz-2024.1 tzdata-2024.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install numpy pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jumlah pertanyaan:  (558, 2)\n",
      "Jumlah pertanyaan:  (17, 2)\n"
     ]
    }
   ],
   "source": [
    "question_path = './data/dataset-question-v2.csv'\n",
    "answer_path = './data/dataset-answer.csv'\n",
    "\n",
    "question_attr = ['pattern', 'tag']\n",
    "answer_attr = ['responses', 'tag']\n",
    "\n",
    "question_data = pd.read_csv(question_path)[question_attr]\n",
    "answer_data = pd.read_csv(answer_path)[answer_attr]\n",
    "\n",
    "# data_answer.head(10)\n",
    "print(\"Jumlah pertanyaan: \", question_data.shape)\n",
    "print(\"Jumlah pertanyaan: \", answer_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pattern</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hi</td>\n",
       "      <td>gr_hi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Halo</td>\n",
       "      <td>gr_ha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Selamat Pagi</td>\n",
       "      <td>gr_pa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Selamat Siang</td>\n",
       "      <td>gr_si</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Selamat Sore</td>\n",
       "      <td>gr_so</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Selamat Malam</td>\n",
       "      <td>gr_ma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Ada program studi apa saja di UIN Sunan Gunung...</td>\n",
       "      <td>prodi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Apa saja program studi yang ada di UIN Sunan G...</td>\n",
       "      <td>prodi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Program studi apa yang tersedia di UIN Sunan G...</td>\n",
       "      <td>prodi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Di UIN Sunan Gunung Djati Bandung, ada program...</td>\n",
       "      <td>prodi</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             pattern    tag\n",
       "0                                                 Hi  gr_hi\n",
       "1                                               Halo  gr_ha\n",
       "2                                       Selamat Pagi  gr_pa\n",
       "3                                      Selamat Siang  gr_si\n",
       "4                                       Selamat Sore  gr_so\n",
       "5                                      Selamat Malam  gr_ma\n",
       "6  Ada program studi apa saja di UIN Sunan Gunung...  prodi\n",
       "7  Apa saja program studi yang ada di UIN Sunan G...  prodi\n",
       "8  Program studi apa yang tersedia di UIN Sunan G...  prodi\n",
       "9  Di UIN Sunan Gunung Djati Bandung, ada program...  prodi"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>responses</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Halo! Apa yang ingin anda cari tahu hari ini?</td>\n",
       "      <td>gr_hi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hi! Apa yang bisa kami bantu?</td>\n",
       "      <td>gr_ha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Selamat Pagi! Apa yang bisa kami bantu untuk m...</td>\n",
       "      <td>gr_pa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Selamat Siang! Apa yang ingin anda cari tahu?</td>\n",
       "      <td>gr_si</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Selamat Sore! Apa yang ingin anda ketahui?</td>\n",
       "      <td>gr_so</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Selamat Malam! Apa yang bisa kami bantu?</td>\n",
       "      <td>gr_ma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>UIN Sunan Gunung Djati Bandung menyelenggaraka...</td>\n",
       "      <td>prodi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SNBP adalah singkatan dari Seleksi Nasional Be...</td>\n",
       "      <td>jm_s1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Untuk jurusan yang bisa dipilih pada Seleksi M...</td>\n",
       "      <td>snbp_jur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Untuk jurusan yang bisa dipilih pada Seleksi M...</td>\n",
       "      <td>snbt_jur</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           responses       tag\n",
       "0      Halo! Apa yang ingin anda cari tahu hari ini?     gr_hi\n",
       "1                      Hi! Apa yang bisa kami bantu?     gr_ha\n",
       "2  Selamat Pagi! Apa yang bisa kami bantu untuk m...     gr_pa\n",
       "3      Selamat Siang! Apa yang ingin anda cari tahu?     gr_si\n",
       "4         Selamat Sore! Apa yang ingin anda ketahui?     gr_so\n",
       "5           Selamat Malam! Apa yang bisa kami bantu?     gr_ma\n",
       "6  UIN Sunan Gunung Djati Bandung menyelenggaraka...     prodi\n",
       "7  SNBP adalah singkatan dari Seleksi Nasional Be...     jm_s1\n",
       "8  Untuk jurusan yang bisa dipilih pada Seleksi M...  snbp_jur\n",
       "9  Untuk jurusan yang bisa dipilih pada Seleksi M...  snbt_jur"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Using cached transformers-4.44.0-py3-none-any.whl (9.5 MB)\n",
      "Collecting filelock (from transformers)\n",
      "  Using cached filelock-3.15.4-py3-none-any.whl (16 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.23.2 (from transformers)\n",
      "  Using cached huggingface_hub-0.24.5-py3-none-any.whl (417 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\haikal\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from transformers) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\haikal\\appdata\\roaming\\python\\python38\\site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\haikal\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\haikal\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from transformers) (2024.7.24)\n",
      "Collecting requests (from transformers)\n",
      "  Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\haikal\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from transformers) (0.4.4)\n",
      "Collecting tokenizers<0.20,>=0.19 (from transformers)\n",
      "  Using cached tokenizers-0.19.1-cp38-none-win_amd64.whl (2.2 MB)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\haikal\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from transformers) (4.66.5)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub<1.0,>=0.23.2->transformers)\n",
      "  Using cached fsspec-2024.6.1-py3-none-any.whl (177 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\haikal\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.5.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\haikal\\appdata\\roaming\\python\\python38\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Collecting charset-normalizer<4,>=2 (from requests->transformers)\n",
      "  Using cached charset_normalizer-3.3.2-cp38-cp38-win_amd64.whl (99 kB)\n",
      "Collecting idna<4,>=2.5 (from requests->transformers)\n",
      "  Using cached idna-3.7-py3-none-any.whl (66 kB)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\haikal\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests->transformers) (2.2.2)\n",
      "Collecting certifi>=2017.4.17 (from requests->transformers)\n",
      "  Using cached certifi-2024.7.4-py3-none-any.whl (162 kB)\n",
      "Installing collected packages: idna, fsspec, filelock, charset-normalizer, certifi, requests, huggingface-hub, tokenizers, transformers\n",
      "Successfully installed certifi-2024.7.4 charset-normalizer-3.3.2 filelock-3.15.4 fsspec-2024.6.1 huggingface-hub-0.24.5 idna-3.7 requests-2.32.3 tokenizers-0.19.1 transformers-4.44.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Using cached tensorflow-2.13.1-cp38-cp38-win_amd64.whl (1.9 kB)\n",
      "INFO: pip is looking at multiple versions of tensorflow to determine which version is compatible with other requirements. This could take a while.\n",
      "  Using cached tensorflow-2.13.0-cp38-cp38-win_amd64.whl (1.9 kB)\n",
      "Collecting tensorflow-intel==2.13.0 (from tensorflow)\n",
      "  Using cached tensorflow_intel-2.13.0-cp38-cp38-win_amd64.whl (276.5 MB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow-intel==2.13.0->tensorflow)\n",
      "  Using cached absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow-intel==2.13.0->tensorflow)\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: flatbuffers>=23.1.21 in c:\\users\\haikal\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (24.3.25)\n",
      "Collecting gast<=0.4.0,>=0.2.1 (from tensorflow-intel==2.13.0->tensorflow)\n",
      "  Using cached gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow-intel==2.13.0->tensorflow)\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Collecting h5py>=2.9.0 (from tensorflow-intel==2.13.0->tensorflow)\n",
      "  Using cached h5py-3.11.0-cp38-cp38-win_amd64.whl (3.0 MB)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\haikal\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: numpy<=1.24.3,>=1.22 in c:\\users\\haikal\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.24.3)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow-intel==2.13.0->tensorflow)\n",
      "  Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\haikal\\appdata\\roaming\\python\\python38\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (24.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\haikal\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (4.25.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\haikal\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (56.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\haikal\\appdata\\roaming\\python\\python38\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\haikal\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in c:\\users\\haikal\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (4.5.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\haikal\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.16.0)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow-intel==2.13.0->tensorflow)\n",
      "  Using cached grpcio-1.65.4-cp38-cp38-win_amd64.whl (4.1 MB)\n",
      "Collecting tensorboard<2.14,>=2.13 (from tensorflow-intel==2.13.0->tensorflow)\n",
      "  Using cached tensorboard-2.13.0-py3-none-any.whl (5.6 MB)\n",
      "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in c:\\users\\haikal\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.13.0)\n",
      "Collecting keras<2.14,>=2.13.1 (from tensorflow-intel==2.13.0->tensorflow)\n",
      "  Using cached keras-2.13.1-py3-none-any.whl (1.7 MB)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\haikal\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\haikal\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.13.0->tensorflow) (0.44.0)\n",
      "Collecting google-auth<3,>=1.6.3 (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow)\n",
      "  Using cached google_auth-2.33.0-py2.py3-none-any.whl (200 kB)\n",
      "Collecting google-auth-oauthlib<1.1,>=0.5 (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow)\n",
      "  Using cached google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
      "Collecting markdown>=2.6.8 (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow)\n",
      "  Using cached Markdown-3.6-py3-none-any.whl (105 kB)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\haikal\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.32.3)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\haikal\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (0.7.2)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow)\n",
      "  Using cached werkzeug-3.0.3-py3-none-any.whl (227 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow)\n",
      "  Using cached cachetools-5.4.0-py3-none-any.whl (9.5 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow)\n",
      "  Using cached pyasn1_modules-0.4.0-py3-none-any.whl (181 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow)\n",
      "  Using cached rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Collecting requests-oauthlib>=0.7.0 (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow)\n",
      "  Using cached requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\haikal\\appdata\\roaming\\python\\python38\\site-packages (from markdown>=2.6.8->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (8.2.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\haikal\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\haikal\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\haikal\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\haikal\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2024.7.4)\n",
      "Collecting MarkupSafe>=2.1.1 (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow)\n",
      "  Using cached MarkupSafe-2.1.5-cp38-cp38-win_amd64.whl (17 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\haikal\\appdata\\roaming\\python\\python38\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.19.2)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in c:\\users\\haikal\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (0.6.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\haikal\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.2.2)\n",
      "Installing collected packages: rsa, pyasn1-modules, opt-einsum, MarkupSafe, keras, h5py, grpcio, google-pasta, gast, cachetools, astunparse, absl-py, werkzeug, requests-oauthlib, markdown, google-auth, google-auth-oauthlib, tensorboard, tensorflow-intel, tensorflow\n",
      "Successfully installed MarkupSafe-2.1.5 absl-py-2.1.0 astunparse-1.6.3 cachetools-5.4.0 gast-0.4.0 google-auth-2.33.0 google-auth-oauthlib-1.0.0 google-pasta-0.2.0 grpcio-1.65.4 h5py-3.11.0 keras-2.13.1 markdown-3.6 opt-einsum-3.3.0 pyasn1-modules-0.4.0 requests-oauthlib-2.0.0 rsa-4.9 tensorboard-2.13.0 tensorflow-2.13.0 tensorflow-intel-2.13.0 werkzeug-3.0.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory\n",
    "from transformers import AutoTokenizer\n",
    "import re\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Haikal\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\huggingface_hub\\file_download.py:159: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Haikal\\.cache\\huggingface\\hub\\models--firqaaa--indo-sentence-bert-base. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\Haikal\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "SBERT_TOKENIZER = 'firqaaa/indo-sentence-bert-base'\n",
    "\n",
    "class Preprocess():\n",
    "    def __init__(self, max_len=128):\n",
    "        self.stemmer = StemmerFactory().create_stemmer()\n",
    "        self.stopword = StopWordRemoverFactory().create_stop_word_remover()\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(SBERT_TOKENIZER)\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def cleaning(self, val):\n",
    "        val = re.sub(r'\\s+', ' ', val)\n",
    "        val = re.sub(\"[^a-zA-Z0-9;]\", \" \", val)\n",
    "        return val\n",
    "    \n",
    "    def casefolding(self, val):\n",
    "        return str(val).lower()\n",
    "    \n",
    "    def stemming(self, val):\n",
    "        return self.stemmer.stem(str(val))\n",
    "    \n",
    "    def stopwordRemoval(self, val):\n",
    "        return self.stopword.remove(str(val))\n",
    "    \n",
    "    def embedding(self, val):\n",
    "        return self.tokenizer.encode_plus(\n",
    "            val,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_token_type_ids=False,\n",
    "            return_tensors='tf'\n",
    "        )\n",
    "    \n",
    "    def preprocessing(self, sentences):\n",
    "        for i in range(len(sentences)):\n",
    "            input = sentences[i]\n",
    "            input = self.cleaning(input)\n",
    "            input = self.casefolding(input)\n",
    "            input = self.stemming(input)\n",
    "            input = self.stopwordremove(input)\n",
    "            sentences[i] = input\n",
    "        return sentences\n",
    "\n",
    "    def tokenizing(self, sentences):\n",
    "        input_ids, attention_mask = [], []\n",
    "        for sentence in sentences:\n",
    "            output = self.embedding(sentence)\n",
    "            input_ids.append(output['input_ids'])\n",
    "            attention_mask.append(output['attention_mask'])\n",
    "        return {\n",
    "            'input_ids': tf.convert_to_tensor(\n",
    "                np.asarray(input_ids).squeeze(),\n",
    "                dtype=tf.int32\n",
    "            ),\n",
    "            'attention_mask': tf.convert_to_tensor(\n",
    "                np.asarray(attention_mask).squeeze(),\n",
    "                dtype=tf.int32\n",
    "            )\n",
    "        }\n",
    "\n",
    "    def preprocess_get_token(self, sentences, display_len=20):\n",
    "        preprocessing = self.preprocessing(sentences)\n",
    "        tokenized = self.tokenizing(preprocessing)\n",
    "        return [self.tokenizer.convert_ids_to_tokens(tokenized['input_ids'][i][:display_len]) for i in range(len(sentences))]\n",
    "\n",
    "preprocess = Preprocess()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Casefolding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apa saja program studi yang ada di UIN Sunan Gunung Djati Bandung?\n",
      "Program studi apa yang tersedia di UIN Sunan Gunung Djati Bandung?\n",
      "Di UIN Sunan Gunung Djati Bandung, ada program studi apa saja?\n"
     ]
    }
   ],
   "source": [
    "sample_texts = question_data['pattern']\n",
    "print(sample_texts[7])\n",
    "print(sample_texts[8])\n",
    "print(sample_texts[9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Before Casefolding</th>\n",
       "      <th>After Casefolding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>548</th>\n",
       "      <td>Program beasiswa di UIN Sunan Gunung Djati Ban...</td>\n",
       "      <td>program beasiswa di uin sunan gunung djati ban...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>549</th>\n",
       "      <td>Apakah beasiswa di UIN Sunan Gunung Djati Band...</td>\n",
       "      <td>apakah beasiswa di uin sunan gunung djati band...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550</th>\n",
       "      <td>Program beasiswa di UIN Sunan Gunung Djati Ban...</td>\n",
       "      <td>program beasiswa di uin sunan gunung djati ban...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>551</th>\n",
       "      <td>Apakah program beasiswa yang ada di UIN Sunan ...</td>\n",
       "      <td>apakah program beasiswa yang ada di uin sunan ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>552</th>\n",
       "      <td>Program beasiswa yang ditawarkan oleh UIN Suna...</td>\n",
       "      <td>program beasiswa yang ditawarkan oleh uin suna...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>553</th>\n",
       "      <td>Apakah program beasiswa disediakan oleh UIN Su...</td>\n",
       "      <td>apakah program beasiswa disediakan oleh uin su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>Program beasiswa di UIN Sunan Gunung Djati Ban...</td>\n",
       "      <td>program beasiswa di uin sunan gunung djati ban...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>Apakah beasiswa di UIN Sunan Gunung Djati Band...</td>\n",
       "      <td>apakah beasiswa di uin sunan gunung djati band...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>Program beasiswa di UIN Sunan Gunung Djati Ban...</td>\n",
       "      <td>program beasiswa di uin sunan gunung djati ban...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>Apakah beasiswa di UIN Sunan Gunung Djati Band...</td>\n",
       "      <td>apakah beasiswa di uin sunan gunung djati band...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Before Casefolding  \\\n",
       "548  Program beasiswa di UIN Sunan Gunung Djati Ban...   \n",
       "549  Apakah beasiswa di UIN Sunan Gunung Djati Band...   \n",
       "550  Program beasiswa di UIN Sunan Gunung Djati Ban...   \n",
       "551  Apakah program beasiswa yang ada di UIN Sunan ...   \n",
       "552  Program beasiswa yang ditawarkan oleh UIN Suna...   \n",
       "553  Apakah program beasiswa disediakan oleh UIN Su...   \n",
       "554  Program beasiswa di UIN Sunan Gunung Djati Ban...   \n",
       "555  Apakah beasiswa di UIN Sunan Gunung Djati Band...   \n",
       "556  Program beasiswa di UIN Sunan Gunung Djati Ban...   \n",
       "557  Apakah beasiswa di UIN Sunan Gunung Djati Band...   \n",
       "\n",
       "                                     After Casefolding  \n",
       "548  program beasiswa di uin sunan gunung djati ban...  \n",
       "549  apakah beasiswa di uin sunan gunung djati band...  \n",
       "550  program beasiswa di uin sunan gunung djati ban...  \n",
       "551  apakah program beasiswa yang ada di uin sunan ...  \n",
       "552  program beasiswa yang ditawarkan oleh uin suna...  \n",
       "553  apakah program beasiswa disediakan oleh uin su...  \n",
       "554  program beasiswa di uin sunan gunung djati ban...  \n",
       "555  apakah beasiswa di uin sunan gunung djati band...  \n",
       "556  program beasiswa di uin sunan gunung djati ban...  \n",
       "557  apakah beasiswa di uin sunan gunung djati band...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess = Preprocess()\n",
    "hasil_casefolding = [preprocess.casefolding(sample) for sample in sample_texts]\n",
    "\n",
    "bf_cf = sample_texts\n",
    "af_cf = hasil_casefolding\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'Before Casefolding': bf_cf,\n",
    "    'After Casefolding': af_cf \n",
    "})\n",
    "\n",
    "df.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Haikal\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Before Cleaning</th>\n",
       "      <th>After Cleaning</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>548</th>\n",
       "      <td>program beasiswa di uin sunan gunung djati ban...</td>\n",
       "      <td>program beasiswa di uin sunan gunung djati ban...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>549</th>\n",
       "      <td>apakah beasiswa di uin sunan gunung djati band...</td>\n",
       "      <td>apakah beasiswa di uin sunan gunung djati band...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550</th>\n",
       "      <td>program beasiswa di uin sunan gunung djati ban...</td>\n",
       "      <td>program beasiswa di uin sunan gunung djati ban...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>551</th>\n",
       "      <td>apakah program beasiswa yang ada di uin sunan ...</td>\n",
       "      <td>apakah program beasiswa yang ada di uin sunan ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>552</th>\n",
       "      <td>program beasiswa yang ditawarkan oleh uin suna...</td>\n",
       "      <td>program beasiswa yang ditawarkan oleh uin suna...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>553</th>\n",
       "      <td>apakah program beasiswa disediakan oleh uin su...</td>\n",
       "      <td>apakah program beasiswa disediakan oleh uin su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>program beasiswa di uin sunan gunung djati ban...</td>\n",
       "      <td>program beasiswa di uin sunan gunung djati ban...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>apakah beasiswa di uin sunan gunung djati band...</td>\n",
       "      <td>apakah beasiswa di uin sunan gunung djati band...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>program beasiswa di uin sunan gunung djati ban...</td>\n",
       "      <td>program beasiswa di uin sunan gunung djati ban...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>apakah beasiswa di uin sunan gunung djati band...</td>\n",
       "      <td>apakah beasiswa di uin sunan gunung djati band...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Before Cleaning  \\\n",
       "548  program beasiswa di uin sunan gunung djati ban...   \n",
       "549  apakah beasiswa di uin sunan gunung djati band...   \n",
       "550  program beasiswa di uin sunan gunung djati ban...   \n",
       "551  apakah program beasiswa yang ada di uin sunan ...   \n",
       "552  program beasiswa yang ditawarkan oleh uin suna...   \n",
       "553  apakah program beasiswa disediakan oleh uin su...   \n",
       "554  program beasiswa di uin sunan gunung djati ban...   \n",
       "555  apakah beasiswa di uin sunan gunung djati band...   \n",
       "556  program beasiswa di uin sunan gunung djati ban...   \n",
       "557  apakah beasiswa di uin sunan gunung djati band...   \n",
       "\n",
       "                                        After Cleaning  \n",
       "548  program beasiswa di uin sunan gunung djati ban...  \n",
       "549  apakah beasiswa di uin sunan gunung djati band...  \n",
       "550  program beasiswa di uin sunan gunung djati ban...  \n",
       "551  apakah program beasiswa yang ada di uin sunan ...  \n",
       "552  program beasiswa yang ditawarkan oleh uin suna...  \n",
       "553  apakah program beasiswa disediakan oleh uin su...  \n",
       "554  program beasiswa di uin sunan gunung djati ban...  \n",
       "555  apakah beasiswa di uin sunan gunung djati band...  \n",
       "556  program beasiswa di uin sunan gunung djati ban...  \n",
       "557  apakah beasiswa di uin sunan gunung djati band...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess = Preprocess()\n",
    "hasil_cleaning = [preprocess.cleaning(sample) for sample in hasil_casefolding]\n",
    "bf_cl = hasil_casefolding\n",
    "af_cl = hasil_cleaning\n",
    "df = pd.DataFrame({\n",
    "    'Before Cleaning': bf_cl,\n",
    "    'After Cleaning': af_cl\n",
    "})\n",
    "df.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Haikal\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Before Stemming</th>\n",
       "      <th>After Stemming</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>548</th>\n",
       "      <td>program beasiswa di uin sunan gunung djati ban...</td>\n",
       "      <td>program beasiswa di uin sunan gunung djati ban...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>549</th>\n",
       "      <td>apakah beasiswa di uin sunan gunung djati band...</td>\n",
       "      <td>apakah beasiswa di uin sunan gunung djati band...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550</th>\n",
       "      <td>program beasiswa di uin sunan gunung djati ban...</td>\n",
       "      <td>program beasiswa di uin sunan gunung djati ban...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>551</th>\n",
       "      <td>apakah program beasiswa yang ada di uin sunan ...</td>\n",
       "      <td>apakah program beasiswa yang ada di uin sunan ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>552</th>\n",
       "      <td>program beasiswa yang ditawarkan oleh uin suna...</td>\n",
       "      <td>program beasiswa yang tawar oleh uin sunan gun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>553</th>\n",
       "      <td>apakah program beasiswa disediakan oleh uin su...</td>\n",
       "      <td>apakah program beasiswa sedia oleh uin sunan g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>program beasiswa di uin sunan gunung djati ban...</td>\n",
       "      <td>program beasiswa di uin sunan gunung djati ban...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>apakah beasiswa di uin sunan gunung djati band...</td>\n",
       "      <td>apakah beasiswa di uin sunan gunung djati band...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>program beasiswa di uin sunan gunung djati ban...</td>\n",
       "      <td>program beasiswa di uin sunan gunung djati ban...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>apakah beasiswa di uin sunan gunung djati band...</td>\n",
       "      <td>apakah beasiswa di uin sunan gunung djati band...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Before Stemming  \\\n",
       "548  program beasiswa di uin sunan gunung djati ban...   \n",
       "549  apakah beasiswa di uin sunan gunung djati band...   \n",
       "550  program beasiswa di uin sunan gunung djati ban...   \n",
       "551  apakah program beasiswa yang ada di uin sunan ...   \n",
       "552  program beasiswa yang ditawarkan oleh uin suna...   \n",
       "553  apakah program beasiswa disediakan oleh uin su...   \n",
       "554  program beasiswa di uin sunan gunung djati ban...   \n",
       "555  apakah beasiswa di uin sunan gunung djati band...   \n",
       "556  program beasiswa di uin sunan gunung djati ban...   \n",
       "557  apakah beasiswa di uin sunan gunung djati band...   \n",
       "\n",
       "                                        After Stemming  \n",
       "548  program beasiswa di uin sunan gunung djati ban...  \n",
       "549  apakah beasiswa di uin sunan gunung djati band...  \n",
       "550  program beasiswa di uin sunan gunung djati ban...  \n",
       "551  apakah program beasiswa yang ada di uin sunan ...  \n",
       "552  program beasiswa yang tawar oleh uin sunan gun...  \n",
       "553  apakah program beasiswa sedia oleh uin sunan g...  \n",
       "554  program beasiswa di uin sunan gunung djati ban...  \n",
       "555  apakah beasiswa di uin sunan gunung djati band...  \n",
       "556  program beasiswa di uin sunan gunung djati ban...  \n",
       "557  apakah beasiswa di uin sunan gunung djati band...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess = Preprocess()\n",
    "hasil_stemming = [preprocess.stemming(sample) for sample in hasil_cleaning]\n",
    "bf_st = hasil_cleaning\n",
    "af_st = hasil_stemming\n",
    "df = pd.DataFrame({\n",
    "    \"Before Stemming\" : bf_st,\n",
    "    \"After Stemming\" : af_st\n",
    "})\n",
    "df.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stopword Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Haikal\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Before Stopword Removal</th>\n",
       "      <th>After Stopword Removal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>548</th>\n",
       "      <td>program beasiswa di uin sunan gunung djati ban...</td>\n",
       "      <td>program beasiswa uin sunan gunung djati bandun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>549</th>\n",
       "      <td>apakah beasiswa di uin sunan gunung djati band...</td>\n",
       "      <td>beasiswa uin sunan gunung djati bandung tawar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550</th>\n",
       "      <td>program beasiswa di uin sunan gunung djati ban...</td>\n",
       "      <td>program beasiswa uin sunan gunung djati bandun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>551</th>\n",
       "      <td>apakah program beasiswa yang ada di uin sunan ...</td>\n",
       "      <td>program beasiswa ada uin sunan gunung djati ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>552</th>\n",
       "      <td>program beasiswa yang tawar oleh uin sunan gun...</td>\n",
       "      <td>program beasiswa tawar uin sunan gunung djati ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>553</th>\n",
       "      <td>apakah program beasiswa sedia oleh uin sunan g...</td>\n",
       "      <td>program beasiswa sedia uin sunan gunung djati ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>program beasiswa di uin sunan gunung djati ban...</td>\n",
       "      <td>program beasiswa uin sunan gunung djati bandun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>apakah beasiswa di uin sunan gunung djati band...</td>\n",
       "      <td>beasiswa uin sunan gunung djati bandung ada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>program beasiswa di uin sunan gunung djati ban...</td>\n",
       "      <td>program beasiswa uin sunan gunung djati bandun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>apakah beasiswa di uin sunan gunung djati band...</td>\n",
       "      <td>beasiswa uin sunan gunung djati bandung beri</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Before Stopword Removal  \\\n",
       "548  program beasiswa di uin sunan gunung djati ban...   \n",
       "549  apakah beasiswa di uin sunan gunung djati band...   \n",
       "550  program beasiswa di uin sunan gunung djati ban...   \n",
       "551  apakah program beasiswa yang ada di uin sunan ...   \n",
       "552  program beasiswa yang tawar oleh uin sunan gun...   \n",
       "553  apakah program beasiswa sedia oleh uin sunan g...   \n",
       "554  program beasiswa di uin sunan gunung djati ban...   \n",
       "555  apakah beasiswa di uin sunan gunung djati band...   \n",
       "556  program beasiswa di uin sunan gunung djati ban...   \n",
       "557  apakah beasiswa di uin sunan gunung djati band...   \n",
       "\n",
       "                                After Stopword Removal  \n",
       "548  program beasiswa uin sunan gunung djati bandun...  \n",
       "549      beasiswa uin sunan gunung djati bandung tawar  \n",
       "550  program beasiswa uin sunan gunung djati bandun...  \n",
       "551  program beasiswa ada uin sunan gunung djati ba...  \n",
       "552  program beasiswa tawar uin sunan gunung djati ...  \n",
       "553  program beasiswa sedia uin sunan gunung djati ...  \n",
       "554  program beasiswa uin sunan gunung djati bandun...  \n",
       "555        beasiswa uin sunan gunung djati bandung ada  \n",
       "556  program beasiswa uin sunan gunung djati bandun...  \n",
       "557       beasiswa uin sunan gunung djati bandung beri  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess = Preprocess()\n",
    "hasil_stopword_removal = [preprocess.stopwordRemoval(sample) for sample in hasil_stemming]\n",
    "bf_sr = hasil_stemming\n",
    "af_sr = hasil_stopword_removal\n",
    "df = pd.DataFrame({\n",
    "    \"Before Stopword Removal\": bf_sr,\n",
    "    \"After Stopword Removal\": af_sr\n",
    "})\n",
    "df.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering (Drop Duplicate Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered data (558, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pattern</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>548</th>\n",
       "      <td>program beasiswa uin sunan gunung djati bandun...</td>\n",
       "      <td>beasiswa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>549</th>\n",
       "      <td>beasiswa uin sunan gunung djati bandung tawar</td>\n",
       "      <td>beasiswa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550</th>\n",
       "      <td>program beasiswa uin sunan gunung djati bandun...</td>\n",
       "      <td>beasiswa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>551</th>\n",
       "      <td>program beasiswa ada uin sunan gunung djati ba...</td>\n",
       "      <td>beasiswa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>552</th>\n",
       "      <td>program beasiswa tawar uin sunan gunung djati ...</td>\n",
       "      <td>beasiswa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>553</th>\n",
       "      <td>program beasiswa sedia uin sunan gunung djati ...</td>\n",
       "      <td>beasiswa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>program beasiswa uin sunan gunung djati bandun...</td>\n",
       "      <td>beasiswa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>beasiswa uin sunan gunung djati bandung ada</td>\n",
       "      <td>beasiswa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>program beasiswa uin sunan gunung djati bandun...</td>\n",
       "      <td>beasiswa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>beasiswa uin sunan gunung djati bandung beri</td>\n",
       "      <td>beasiswa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               pattern       tag\n",
       "548  program beasiswa uin sunan gunung djati bandun...  beasiswa\n",
       "549      beasiswa uin sunan gunung djati bandung tawar  beasiswa\n",
       "550  program beasiswa uin sunan gunung djati bandun...  beasiswa\n",
       "551  program beasiswa ada uin sunan gunung djati ba...  beasiswa\n",
       "552  program beasiswa tawar uin sunan gunung djati ...  beasiswa\n",
       "553  program beasiswa sedia uin sunan gunung djati ...  beasiswa\n",
       "554  program beasiswa uin sunan gunung djati bandun...  beasiswa\n",
       "555        beasiswa uin sunan gunung djati bandung ada  beasiswa\n",
       "556  program beasiswa uin sunan gunung djati bandun...  beasiswa\n",
       "557       beasiswa uin sunan gunung djati bandung beri  beasiswa"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_be_filtered = pd.DataFrame({\n",
    "    \"pattern\": hasil_stopword_removal,\n",
    "    \"tag\": question_data['tag']\n",
    "})\n",
    "to_be_filtered.head(10)\n",
    "hasil_filtering = to_be_filtered\n",
    "\n",
    "hasil_filtering.to_csv('data/preprocessed-data-v2.csv', index=False)\n",
    "\n",
    "print('Filtered data', hasil_filtering.shape)\n",
    "hasil_filtering.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total data:  (404, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pattern</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>program beasiswa uin sunan gunung djati bandun...</td>\n",
       "      <td>beasiswa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>program beasiswa beri uin sunan gunung djati b...</td>\n",
       "      <td>beasiswa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>program beasiswa uin sunan gunung djati bandun...</td>\n",
       "      <td>beasiswa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>beasiswa uin sunan gunung djati bandung tawar</td>\n",
       "      <td>beasiswa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>program beasiswa uin sunan gunung djati bandun...</td>\n",
       "      <td>beasiswa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>program beasiswa ada uin sunan gunung djati ba...</td>\n",
       "      <td>beasiswa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>program beasiswa tawar uin sunan gunung djati ...</td>\n",
       "      <td>beasiswa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>program beasiswa uin sunan gunung djati bandun...</td>\n",
       "      <td>beasiswa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>beasiswa uin sunan gunung djati bandung ada</td>\n",
       "      <td>beasiswa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>beasiswa uin sunan gunung djati bandung beri</td>\n",
       "      <td>beasiswa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               pattern       tag\n",
       "394  program beasiswa uin sunan gunung djati bandun...  beasiswa\n",
       "395  program beasiswa beri uin sunan gunung djati b...  beasiswa\n",
       "396  program beasiswa uin sunan gunung djati bandun...  beasiswa\n",
       "397      beasiswa uin sunan gunung djati bandung tawar  beasiswa\n",
       "398  program beasiswa uin sunan gunung djati bandun...  beasiswa\n",
       "399  program beasiswa ada uin sunan gunung djati ba...  beasiswa\n",
       "400  program beasiswa tawar uin sunan gunung djati ...  beasiswa\n",
       "401  program beasiswa uin sunan gunung djati bandun...  beasiswa\n",
       "402        beasiswa uin sunan gunung djati bandung ada  beasiswa\n",
       "403       beasiswa uin sunan gunung djati bandung beri  beasiswa"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('data/preprocessed-data-v2.csv')\n",
    "print(\"Total data: \", dataset.shape)\n",
    "dataset.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Labelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Defining labels\n",
    "# label_list = dataset['tag'].drop_duplicates()\n",
    "# LABELS = label_list.tolist()\n",
    "# len(LABELS), LABELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Give 0 as initial value\n",
    "# labelled_data = dataset.copy()\n",
    "# labelled_data[LABELS] = 0\n",
    "# labels = pd.Series(label_list)\n",
    "\n",
    "# for i, row in labelled_data.iterrows():\n",
    "#     tag = row['tag'].split(';')\n",
    "#     labelled_data.loc[i, tag] = 1\n",
    "# labelled_data.tail(1)\n",
    "# # labelled_data[LABELS].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sentence_transformers import SentenceTransformer\n",
    "# sentences = []\n",
    "# for sentence in dataset['pattern']:\n",
    "#     sentences.append(sentence)\n",
    "\n",
    "# model = SentenceTransformer('firqaaa/indo-sentence-bert-base')\n",
    "# embeddings = model.encode(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def low_confident(indexes):\n",
    "#     tags = []\n",
    "#     data = dataset.to_numpy().tolist()\n",
    "#     pos = 0\n",
    "#     for tag in data:\n",
    "#         for id in indexes:\n",
    "#             if(id == pos):\n",
    "#                 tags.append(tag)\n",
    "#         pos += 1\n",
    "#     tags = pd.DataFrame(tags)\n",
    "#     tags = tags.drop_duplicates()\n",
    "#     return tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# asked_quetion = 'Informasi seputar biaya UKT di UIN Sunan Gunung Djati Bandung'\n",
    "# encoded_question = model.encode(asked_quetion)\n",
    "# result = np.array(model.similarity(encoded_question, embeddings))\n",
    "# highestIndex = np.argmax(result)\n",
    "# highestVal = np.max(result)\n",
    "# tag = dataset.loc[highestIndex]['tag']\n",
    "\n",
    "# print\n",
    "# highestIndex, highestVal, tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # get confidents higher than 0.5\n",
    "# confidents = []\n",
    "# indexes = []\n",
    "# pos = 0\n",
    "\n",
    "# for item in result:\n",
    "#     for value in item:\n",
    "#         if(value >= 0.8):\n",
    "#             confidents.append(value)\n",
    "#             indexes.append(pos)\n",
    "#         elif(value < 0.8):\n",
    "#             recommended_tags = low_confident(indexes)\n",
    "#             recommended_tags\n",
    "#         pos += 1\n",
    "# confidents, indexes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import AutoTokenizer, AutoModel\n",
    "# import torch\n",
    "\n",
    "\n",
    "# #Mean Pooling - Take attention mask into account for correct averaging\n",
    "# def mean_pooling(model_output, attention_mask):\n",
    "#     token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n",
    "#     input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "#     return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "\n",
    "\n",
    "# # Sentences we want sentence embeddings for\n",
    "# sentences = [\"Ibukota Perancis adalah Paris\", \n",
    "#              \"Menara Eifel terletak di Paris, Perancis\", \n",
    "#              \"Pizza adalah makanan khas Italia\", \n",
    "#              \"Saya kuliah di Carneige Mellon University\"]\n",
    "\n",
    "\n",
    "# # Load model from HuggingFace Hub\n",
    "# tokenizer = AutoTokenizer.from_pretrained('firqaaa/indo-sentence-bert-base')\n",
    "# model = AutoModel.from_pretrained('firqaaa/indo-sentence-bert-base')\n",
    "\n",
    "# # Tokenize sentences\n",
    "# encoded_input = tokenizer(sentences, padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "# # Compute token embeddings\n",
    "# with torch.no_grad():\n",
    "#     model_output = model(**encoded_input)\n",
    "\n",
    "# # Perform pooling. In this case, mean pooling.\n",
    "# sentence_embeddings = mean_pooling(model_output, encoded_input['attention_mask'])\n",
    "\n",
    "# print(\"Sentence embeddings:\")\n",
    "# print(sentence_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tuned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install -U \"sentence-transformers[train]\" \" transformers[torch]\" accelerate datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Import libraries\n",
    "# from datasets import load_dataset\n",
    "# from sentence_transformers import (\n",
    "#     SentenceTransformer,\n",
    "#     SentenceTransformerTrainer,\n",
    "#     SentenceTransformerTrainingArguments\n",
    "# )\n",
    "# from sentence_transformers.losses import CoSENTLoss\n",
    "# from sentence_transformers.training_args import BatchSamplers\n",
    "# from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator, SimilarityFunction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define model\n",
    "# model = SentenceTransformer(\"firqaaa/indo-sentence-bert-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define datasets\n",
    "# train_dataset = load_dataset(\"csv\", data_files=\"data/preprocessed-data.csv\")\n",
    "# test_dataset = load_dataset(\"csv\", data_files=\"data/dataset-question.csv\")\n",
    "# eval_dataset = load_dataset(\"csv\", data_files=\"data/dataset-eval.csv\")\n",
    "# train_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define loss function (CoSENTLoss | Cosine Sentence Loss -> Returning float similarity score)\n",
    "# loss = CoSENTLoss(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Specify training args\n",
    "# args = SentenceTransformerTrainingArguments(\n",
    "#     output_dir=\"fine-tuned/sbert-fine-tuned-chatPMB\",\n",
    "#     num_train_epochs=50,\n",
    "#     per_device_train_batch_size=24,\n",
    "#     per_device_eval_batch_size=24,\n",
    "#     learning_rate=2e-5,\n",
    "#     warmup_ratio=0.1,\n",
    "#     batch_sampler=BatchSamplers.NO_DUPLICATES,\n",
    "#     eval_strategy=\"steps\",\n",
    "#     eval_steps=100,\n",
    "#     save_strategy=\"steps\",\n",
    "#     save_steps=100,\n",
    "#     save_total_limit=2,\n",
    "#     logging_steps=100,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Creating eval dataset\n",
    "# train_patterns = pd.read_csv('data/preprocessed-data.csv')['pattern']\n",
    "# test_patterns = pd.read_csv('data/dataset-question.csv')['pattern']\n",
    "# test_patterns = test_patterns.iloc[:-12]\n",
    "# train_patterns, test_patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embed_train = model.encode(train_patterns)\n",
    "# embed_test = model.encode(test_patterns)\n",
    "# # embed_test, embed_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scores = []\n",
    "# temp = 0\n",
    "# result = np.array(model.similarity(embed_train, embed_test))\n",
    "# # result\n",
    "# for val in result:\n",
    "#     for data in val:\n",
    "#         if(temp<data):\n",
    "#             temp=data\n",
    "#     scores.append(temp)\n",
    "# dev = pd.DataFrame({\n",
    "#     \"train_patterns\": train_patterns,\n",
    "#     \"test_patterns\": test_patterns,\n",
    "#     \"score\": scores\n",
    "# })\n",
    "# # dev.to_csv('data/dataset-eval.csv')\n",
    "# dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install seaborn matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "# plt.figure(figsize=(15, 15))\n",
    "# sns.heatmap(\n",
    "#     result,\n",
    "#     annot=True,\n",
    "#     fmt=\"d\",\n",
    "#     cmap=\"Blues\",\n",
    "#     xticklabels=train_patterns,\n",
    "#     yticklabels=test_patterns,\n",
    "# )\n",
    "# plt.xlabel(\"Predicted labels\")\n",
    "# plt.ylabel(\"True labels\")\n",
    "# plt.title(\"Training Data\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create evaluator & evaluate the base model\n",
    "# dev_evaluator = EmbeddingSimilarityEvaluator(\n",
    "#     sentences1=dev[\"train_patterns\"],\n",
    "#     sentences2=dev[\"test_patterns\"],\n",
    "#     scores=dev[\"score\"],\n",
    "#     main_similarity=SimilarityFunction.COSINE,\n",
    "#     name=\"sts-dev\",\n",
    "# )\n",
    "# dev_evaluator(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer = SentenceTransformerTrainer(\n",
    "#     model=model,\n",
    "#     args=args,\n",
    "#     train_dataset=train_dataset,\n",
    "#     eval_dataset=eval_dataset,\n",
    "#     loss=loss,\n",
    "#     evaluator=dev_evaluator,\n",
    "# )\n",
    "# trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save_pretrained(\"fine-tuned/models/chatPMB-SBERT-pretrained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_evaluator = EmbeddingSimilarityEvaluator(\n",
    "#     sentences1=dev[\"train_patterns\"],\n",
    "#     sentences2=dev[\"test_patterns\"],\n",
    "#     scores=dev[\"score\"],\n",
    "#     main_similarity=SimilarityFunction.COSINE,\n",
    "#     name=\"sts-dev\",\n",
    "# )\n",
    "# test_evaluator(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
