{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install & Load Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: accelerate in c:\\projects\\uni\\python\\skripsi\\sbert_chatbot\\.venv\\lib\\site-packages (0.32.1)\n",
      "Requirement already satisfied: datasets in c:\\projects\\uni\\python\\skripsi\\sbert_chatbot\\.venv\\lib\\site-packages (2.20.0)\n",
      "Requirement already satisfied: sentence-transformers[train] in c:\\projects\\uni\\python\\skripsi\\sbert_chatbot\\.venv\\lib\\site-packages (3.0.1)\n",
      "Requirement already satisfied: transformers[torch] in c:\\projects\\uni\\python\\skripsi\\sbert_chatbot\\.venv\\lib\\site-packages (4.42.4)\n",
      "Requirement already satisfied: tqdm in c:\\projects\\uni\\python\\skripsi\\sbert_chatbot\\.venv\\lib\\site-packages (from sentence-transformers[train]) (4.66.4)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\projects\\uni\\python\\skripsi\\sbert_chatbot\\.venv\\lib\\site-packages (from sentence-transformers[train]) (2.3.0)\n",
      "Requirement already satisfied: numpy in c:\\projects\\uni\\python\\skripsi\\sbert_chatbot\\.venv\\lib\\site-packages (from sentence-transformers[train]) (1.26.4)\n",
      "Requirement already satisfied: scikit-learn in c:\\projects\\uni\\python\\skripsi\\sbert_chatbot\\.venv\\lib\\site-packages (from sentence-transformers[train]) (1.5.0)\n",
      "Requirement already satisfied: scipy in c:\\projects\\uni\\python\\skripsi\\sbert_chatbot\\.venv\\lib\\site-packages (from sentence-transformers[train]) (1.13.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.15.1 in c:\\projects\\uni\\python\\skripsi\\sbert_chatbot\\.venv\\lib\\site-packages (from sentence-transformers[train]) (0.23.2)\n",
      "Requirement already satisfied: Pillow in c:\\projects\\uni\\python\\skripsi\\sbert_chatbot\\.venv\\lib\\site-packages (from sentence-transformers[train]) (10.3.0)\n",
      "Requirement already satisfied: filelock in c:\\projects\\uni\\python\\skripsi\\sbert_chatbot\\.venv\\lib\\site-packages (from transformers[torch]) (3.14.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\projects\\uni\\python\\skripsi\\sbert_chatbot\\.venv\\lib\\site-packages (from transformers[torch]) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\projects\\uni\\python\\skripsi\\sbert_chatbot\\.venv\\lib\\site-packages (from transformers[torch]) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\projects\\uni\\python\\skripsi\\sbert_chatbot\\.venv\\lib\\site-packages (from transformers[torch]) (2024.5.15)\n",
      "Requirement already satisfied: requests in c:\\projects\\uni\\python\\skripsi\\sbert_chatbot\\.venv\\lib\\site-packages (from transformers[torch]) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\projects\\uni\\python\\skripsi\\sbert_chatbot\\.venv\\lib\\site-packages (from transformers[torch]) (0.4.3)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in c:\\projects\\uni\\python\\skripsi\\sbert_chatbot\\.venv\\lib\\site-packages (from transformers[torch]) (0.19.1)\n",
      "Requirement already satisfied: psutil in c:\\projects\\uni\\python\\skripsi\\sbert_chatbot\\.venv\\lib\\site-packages (from accelerate) (6.0.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\projects\\uni\\python\\skripsi\\sbert_chatbot\\.venv\\lib\\site-packages (from datasets) (16.1.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in c:\\projects\\uni\\python\\skripsi\\sbert_chatbot\\.venv\\lib\\site-packages (from datasets) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\projects\\uni\\python\\skripsi\\sbert_chatbot\\.venv\\lib\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\projects\\uni\\python\\skripsi\\sbert_chatbot\\.venv\\lib\\site-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: xxhash in c:\\projects\\uni\\python\\skripsi\\sbert_chatbot\\.venv\\lib\\site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in c:\\projects\\uni\\python\\skripsi\\sbert_chatbot\\.venv\\lib\\site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.5.0,>=2023.1.0 in c:\\projects\\uni\\python\\skripsi\\sbert_chatbot\\.venv\\lib\\site-packages (from fsspec[http]<=2024.5.0,>=2023.1.0->datasets) (2024.5.0)\n",
      "Requirement already satisfied: aiohttp in c:\\projects\\uni\\python\\skripsi\\sbert_chatbot\\.venv\\lib\\site-packages (from datasets) (3.9.5)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\projects\\uni\\python\\skripsi\\sbert_chatbot\\.venv\\lib\\site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\projects\\uni\\python\\skripsi\\sbert_chatbot\\.venv\\lib\\site-packages (from aiohttp->datasets) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\projects\\uni\\python\\skripsi\\sbert_chatbot\\.venv\\lib\\site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\projects\\uni\\python\\skripsi\\sbert_chatbot\\.venv\\lib\\site-packages (from aiohttp->datasets) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\projects\\uni\\python\\skripsi\\sbert_chatbot\\.venv\\lib\\site-packages (from aiohttp->datasets) (1.9.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\projects\\uni\\python\\skripsi\\sbert_chatbot\\.venv\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers[train]) (4.12.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\projects\\uni\\python\\skripsi\\sbert_chatbot\\.venv\\lib\\site-packages (from requests->transformers[torch]) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\projects\\uni\\python\\skripsi\\sbert_chatbot\\.venv\\lib\\site-packages (from requests->transformers[torch]) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\projects\\uni\\python\\skripsi\\sbert_chatbot\\.venv\\lib\\site-packages (from requests->transformers[torch]) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\projects\\uni\\python\\skripsi\\sbert_chatbot\\.venv\\lib\\site-packages (from requests->transformers[torch]) (2024.6.2)\n",
      "Requirement already satisfied: sympy in c:\\projects\\uni\\python\\skripsi\\sbert_chatbot\\.venv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers[train]) (1.12.1)\n",
      "Requirement already satisfied: networkx in c:\\projects\\uni\\python\\skripsi\\sbert_chatbot\\.venv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers[train]) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\projects\\uni\\python\\skripsi\\sbert_chatbot\\.venv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers[train]) (3.1.4)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\projects\\uni\\python\\skripsi\\sbert_chatbot\\.venv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers[train]) (2021.4.0)\n",
      "Requirement already satisfied: colorama in c:\\projects\\uni\\python\\skripsi\\sbert_chatbot\\.venv\\lib\\site-packages (from tqdm->sentence-transformers[train]) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\projects\\uni\\python\\skripsi\\sbert_chatbot\\.venv\\lib\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\projects\\uni\\python\\skripsi\\sbert_chatbot\\.venv\\lib\\site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\projects\\uni\\python\\skripsi\\sbert_chatbot\\.venv\\lib\\site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\projects\\uni\\python\\skripsi\\sbert_chatbot\\.venv\\lib\\site-packages (from scikit-learn->sentence-transformers[train]) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\projects\\uni\\python\\skripsi\\sbert_chatbot\\.venv\\lib\\site-packages (from scikit-learn->sentence-transformers[train]) (3.5.0)\n",
      "Requirement already satisfied: intel-openmp==2021.* in c:\\projects\\uni\\python\\skripsi\\sbert_chatbot\\.venv\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=1.11.0->sentence-transformers[train]) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in c:\\projects\\uni\\python\\skripsi\\sbert_chatbot\\.venv\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=1.11.0->sentence-transformers[train]) (2021.12.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\projects\\uni\\python\\skripsi\\sbert_chatbot\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\projects\\uni\\python\\skripsi\\sbert_chatbot\\.venv\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers[train]) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in c:\\projects\\uni\\python\\skripsi\\sbert_chatbot\\.venv\\lib\\site-packages (from sympy->torch>=1.11.0->sentence-transformers[train]) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install -U \"sentence-transformers[train]\" \" transformers[torch]\" accelerate datasets pandas matplotlib seaborn numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "from datasets import load_dataset, Dataset\n",
    "from sentence_transformers import (\n",
    "    SentenceTransformer,\n",
    "    SentenceTransformerTrainer,\n",
    "    SentenceTransformerTrainingArguments\n",
    ")\n",
    "from sentence_transformers.losses import CoSENTLoss\n",
    "from sentence_transformers.training_args import BatchSamplers\n",
    "from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator, SimilarityFunction\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tuning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model\n",
    "model = SentenceTransformer(\"firqaaa/indo-sentence-bert-base\")\n",
    "\n",
    "# Define loss function (CoSENTLoss | Cosine Sentence Loss -> Returning float similarity score)\n",
    "loss = CoSENTLoss(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 247 examples [00:00, 3249.79 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(DatasetDict({\n",
       "     train: Dataset({\n",
       "         features: ['pattern', 'tag'],\n",
       "         num_rows: 247\n",
       "     })\n",
       " }),\n",
       " DatasetDict({\n",
       "     train: Dataset({\n",
       "         features: ['pattern', 'tag'],\n",
       "         num_rows: 259\n",
       "     })\n",
       " }))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define datasets\n",
    "train_dataset = load_dataset(\"csv\", data_files=\"data/preprocessed-data.csv\")\n",
    "test_dataset = load_dataset(\"csv\", data_files=\"data/dataset-question.csv\")\n",
    "eval_dataset = load_dataset(\"csv\", data_files=\"data/dataset-eval.csv\")\n",
    "train_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify training args\n",
    "args = SentenceTransformerTrainingArguments(\n",
    "    output_dir=\"fine-tuned/sbert-fine-tuned-chatPMB\",\n",
    "    num_train_epochs=100,\n",
    "    per_device_train_batch_size=24,\n",
    "    per_device_eval_batch_size=24,\n",
    "    learning_rate=2e-5,\n",
    "    warmup_ratio=0.1,\n",
    "    batch_sampler=BatchSamplers.NO_DUPLICATES,\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=100,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=100,\n",
    "    save_total_limit=2,\n",
    "    logging_steps=100,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(247,) (247,)\n"
     ]
    }
   ],
   "source": [
    "# Creating eval dataset\n",
    "train_patterns = pd.read_csv('data/preprocessed-data.csv')['pattern']\n",
    "test_patterns = pd.read_csv('data/dataset-question.csv')['pattern']\n",
    "test_patterns = test_patterns.iloc[:-12]\n",
    "print(train_patterns.shape, test_patterns.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_train = model.encode(train_patterns)\n",
    "embed_test = model.encode(test_patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_1</th>\n",
       "      <th>sentence_2</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>uin sunan gunung djati bandung punya beasiswa</td>\n",
       "      <td>Bisakah Anda memberitahu saya apakah di UIN Su...</td>\n",
       "      <td>0.845474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>info soal beasiswa uin sunan gunung djati bandung</td>\n",
       "      <td>Dapatkah Anda memberikan informasi tentang ada...</td>\n",
       "      <td>0.864547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>beasiswa uin sunan gunung djati bandung info l...</td>\n",
       "      <td>Mohon penjelasan apakah ada program beasiswa d...</td>\n",
       "      <td>0.815647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>minta info dong uin sunan gunung djati bandung...</td>\n",
       "      <td>Saya ingin menanyakan apakah di UIN Sunan Gunu...</td>\n",
       "      <td>0.862830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>beasiswa uin sunan gunung djati bandung gak sih</td>\n",
       "      <td>Mohon konfirmasi apakah UIN Sunan Gunung Djati...</td>\n",
       "      <td>0.779388</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence_1  \\\n",
       "242      uin sunan gunung djati bandung punya beasiswa   \n",
       "243  info soal beasiswa uin sunan gunung djati bandung   \n",
       "244  beasiswa uin sunan gunung djati bandung info l...   \n",
       "245  minta info dong uin sunan gunung djati bandung...   \n",
       "246    beasiswa uin sunan gunung djati bandung gak sih   \n",
       "\n",
       "                                            sentence_2     label  \n",
       "242  Bisakah Anda memberitahu saya apakah di UIN Su...  0.845474  \n",
       "243  Dapatkah Anda memberikan informasi tentang ada...  0.864547  \n",
       "244  Mohon penjelasan apakah ada program beasiswa d...  0.815647  \n",
       "245  Saya ingin menanyakan apakah di UIN Sunan Gunu...  0.862830  \n",
       "246  Mohon konfirmasi apakah UIN Sunan Gunung Djati...  0.779388  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = []\n",
    "sentences_1 = []\n",
    "sentences_2 = []\n",
    "\n",
    "for i in range(len(test_patterns)):\n",
    "    data = model.similarity(embed_train[int(i)], embed_test[int(i)])\n",
    "    data = float(data[0][0])\n",
    "    s1 = train_patterns[int(i)]\n",
    "    s2 = test_patterns[int(i)]\n",
    "    sentences_1.append(s1)\n",
    "    sentences_2.append(s2)\n",
    "    scores.append(data)\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"sentence_1\": sentences_1,\n",
    "    \"sentence_2\": sentences_2,\n",
    "    \"label\": scores,\n",
    "})\n",
    "df.to_csv('data/fine-tuned-dataset.csv')\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "Batches: 100%|██████████| 16/16 [00:19<00:00,  1.22s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "Batches: 100%|██████████| 16/16 [00:19<00:00,  1.21s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'train-evaluator_pearson_cosine': 0.9999999999998636,\n",
       " 'train-evaluator_spearman_cosine': 0.999995022854554,\n",
       " 'train-evaluator_pearson_manhattan': 0.9370126899993185,\n",
       " 'train-evaluator_spearman_manhattan': 0.9988644150622566,\n",
       " 'train-evaluator_pearson_euclidean': 0.9386299766186968,\n",
       " 'train-evaluator_spearman_euclidean': 0.9999920365732318,\n",
       " 'train-evaluator_pearson_dot': 0.9999999999999291,\n",
       " 'train-evaluator_spearman_dot': 0.9999962173872572,\n",
       " 'train-evaluator_pearson_max': 0.9999999999999291,\n",
       " 'train-evaluator_spearman_max': 0.9999962173872572}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create evaluator & evaluate the base model\n",
    "dev_evaluator = EmbeddingSimilarityEvaluator(\n",
    "    sentences1=df[\"sentence_1\"],\n",
    "    sentences2=df[\"sentence_2\"],\n",
    "    scores=df[\"label\"],\n",
    "    main_similarity=SimilarityFunction.COSINE,\n",
    "    show_progress_bar=True,\n",
    "    precision=\"float32\",\n",
    "    name=\"train-evaluator\",\n",
    ")\n",
    "dev_evaluator(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Dataset({\n",
       "     features: ['sentence_1', 'sentence_2', 'label'],\n",
       "     num_rows: 247\n",
       " }),\n",
       " DatasetDict({\n",
       "     train: Dataset({\n",
       "         features: ['pattern', 'tag'],\n",
       "         num_rows: 247\n",
       "     })\n",
       " }))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data = Dataset.from_dict(df)\n",
    "training_data, train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1100 [6:13:51<?, ?it/s]\n",
      "  0%|          | 0/1100 [03:24<?, ?it/s]\n",
      "  9%|▉         | 100/1100 [20:12<2:44:34,  9.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.1953, 'grad_norm': 155.7838592529297, 'learning_rate': 1.8181818181818182e-05, 'epoch': 9.09}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 16/16 [00:13<00:00,  1.17it/s]\n",
      "Batches: 100%|██████████| 16/16 [00:18<00:00,  1.14s/it]\n",
      "  9%|▉         | 100/1100 [20:45<2:44:34,  9.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_train-evaluator_pearson_cosine': 0.8093898640561992, 'eval_train-evaluator_spearman_cosine': 0.824334797888826, 'eval_train-evaluator_pearson_manhattan': 0.7798400142510288, 'eval_train-evaluator_spearman_manhattan': 0.8241380285194678, 'eval_train-evaluator_pearson_euclidean': 0.7826685689888642, 'eval_train-evaluator_spearman_euclidean': 0.8243323361809636, 'eval_train-evaluator_pearson_dot': 0.8093898617977469, 'eval_train-evaluator_spearman_dot': 0.8243353547107994, 'eval_train-evaluator_pearson_max': 0.8093898640561992, 'eval_train-evaluator_spearman_max': 0.8243353547107994, 'eval_runtime': 32.1151, 'eval_samples_per_second': 0.0, 'eval_steps_per_second': 0.0, 'epoch': 9.09}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 200/1100 [42:25<2:37:33, 10.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.8985, 'grad_norm': 38.27452087402344, 'learning_rate': 1.8181818181818182e-05, 'epoch': 18.18}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 16/16 [00:12<00:00,  1.29it/s]\n",
      "Batches: 100%|██████████| 16/16 [00:17<00:00,  1.07s/it]\n",
      " 18%|█▊        | 200/1100 [42:55<2:37:33, 10.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_train-evaluator_pearson_cosine': 0.7442912049979398, 'eval_train-evaluator_spearman_cosine': 0.7888823035658308, 'eval_train-evaluator_pearson_manhattan': 0.7274242660573856, 'eval_train-evaluator_spearman_manhattan': 0.7867099133952896, 'eval_train-evaluator_pearson_euclidean': 0.7317339537045231, 'eval_train-evaluator_spearman_euclidean': 0.788879947729617, 'eval_train-evaluator_pearson_dot': 0.7442912135059014, 'eval_train-evaluator_spearman_dot': 0.7888815736169931, 'eval_train-evaluator_pearson_max': 0.7442912135059014, 'eval_train-evaluator_spearman_max': 0.7888823035658308, 'eval_runtime': 29.6626, 'eval_samples_per_second': 0.0, 'eval_steps_per_second': 0.0, 'epoch': 18.18}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 300/1100 [1:03:29<2:41:00, 12.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.4653, 'grad_norm': 33.83391571044922, 'learning_rate': 1.616161616161616e-05, 'epoch': 27.27}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 16/16 [00:13<00:00,  1.18it/s]\n",
      "Batches: 100%|██████████| 16/16 [00:18<00:00,  1.14s/it]\n",
      " 27%|██▋       | 300/1100 [1:04:01<2:41:00, 12.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_train-evaluator_pearson_cosine': 0.7314217791145274, 'eval_train-evaluator_spearman_cosine': 0.8063740270502889, 'eval_train-evaluator_pearson_manhattan': 0.7153677105089545, 'eval_train-evaluator_spearman_manhattan': 0.8049270530033896, 'eval_train-evaluator_pearson_euclidean': 0.7192350350987506, 'eval_train-evaluator_spearman_euclidean': 0.8063716189786079, 'eval_train-evaluator_pearson_dot': 0.731421782423749, 'eval_train-evaluator_spearman_dot': 0.8063701741459546, 'eval_train-evaluator_pearson_max': 0.731421782423749, 'eval_train-evaluator_spearman_max': 0.8063740270502889, 'eval_runtime': 31.8666, 'eval_samples_per_second': 0.0, 'eval_steps_per_second': 0.0, 'epoch': 27.27}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▋      | 400/1100 [1:22:51<2:04:50, 10.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.2363, 'grad_norm': 57.30267333984375, 'learning_rate': 1.4141414141414143e-05, 'epoch': 36.36}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 16/16 [00:12<00:00,  1.32it/s]\n",
      "Batches: 100%|██████████| 16/16 [00:15<00:00,  1.03it/s]\n",
      " 36%|███▋      | 400/1100 [1:23:19<2:04:50, 10.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_train-evaluator_pearson_cosine': 0.7352591247935228, 'eval_train-evaluator_spearman_cosine': 0.8007669601231745, 'eval_train-evaluator_pearson_manhattan': 0.7145743915983467, 'eval_train-evaluator_spearman_manhattan': 0.8001083822668705, 'eval_train-evaluator_pearson_euclidean': 0.7178974343838966, 'eval_train-evaluator_spearman_euclidean': 0.8007645687958561, 'eval_train-evaluator_pearson_dot': 0.7352591439893935, 'eval_train-evaluator_spearman_dot': 0.8007645687958561, 'eval_train-evaluator_pearson_max': 0.7352591439893935, 'eval_train-evaluator_spearman_max': 0.8007669601231745, 'eval_runtime': 27.698, 'eval_samples_per_second': 0.0, 'eval_steps_per_second': 0.0, 'epoch': 36.36}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 500/1100 [1:41:29<2:04:50, 12.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.9939, 'grad_norm': 40.00443649291992, 'learning_rate': 1.2121212121212122e-05, 'epoch': 45.45}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 16/16 [00:14<00:00,  1.13it/s]\n",
      "Batches: 100%|██████████| 16/16 [00:19<00:00,  1.20s/it]\n",
      " 45%|████▌     | 500/1100 [1:42:02<2:04:50, 12.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_train-evaluator_pearson_cosine': 0.7199298898939839, 'eval_train-evaluator_spearman_cosine': 0.7922882722133623, 'eval_train-evaluator_pearson_manhattan': 0.6975104350879451, 'eval_train-evaluator_spearman_manhattan': 0.7919888703135487, 'eval_train-evaluator_pearson_euclidean': 0.7015712284662784, 'eval_train-evaluator_spearman_euclidean': 0.7922859062059172, 'eval_train-evaluator_pearson_dot': 0.7199298913934264, 'eval_train-evaluator_spearman_dot': 0.7922865264965321, 'eval_train-evaluator_pearson_max': 0.7199298913934264, 'eval_train-evaluator_spearman_max': 0.7922882722133623, 'eval_runtime': 33.359, 'eval_samples_per_second': 0.0, 'eval_steps_per_second': 0.0, 'epoch': 45.45}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 600/1100 [2:00:39<1:37:08, 11.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.7431, 'grad_norm': 114.22269439697266, 'learning_rate': 1.0101010101010103e-05, 'epoch': 54.55}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 16/16 [00:11<00:00,  1.36it/s]\n",
      "Batches: 100%|██████████| 16/16 [00:16<00:00,  1.01s/it]\n",
      " 55%|█████▍    | 600/1100 [2:01:07<1:37:08, 11.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_train-evaluator_pearson_cosine': 0.7072685301315268, 'eval_train-evaluator_spearman_cosine': 0.7847795328218323, 'eval_train-evaluator_pearson_manhattan': 0.6803517783032225, 'eval_train-evaluator_spearman_manhattan': 0.7847102964362085, 'eval_train-evaluator_pearson_euclidean': 0.6823756592952265, 'eval_train-evaluator_spearman_euclidean': 0.7847771892377071, 'eval_train-evaluator_pearson_dot': 0.7072685016882372, 'eval_train-evaluator_spearman_dot': 0.7847707077360904, 'eval_train-evaluator_pearson_max': 0.7072685301315268, 'eval_train-evaluator_spearman_max': 0.7847795328218323, 'eval_runtime': 28.0607, 'eval_samples_per_second': 0.0, 'eval_steps_per_second': 0.0, 'epoch': 54.55}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▎   | 700/1100 [2:19:56<1:14:49, 11.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.6148, 'grad_norm': 23.569095611572266, 'learning_rate': 8.08080808080808e-06, 'epoch': 63.64}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 16/16 [00:12<00:00,  1.32it/s]\n",
      "Batches: 100%|██████████| 16/16 [00:16<00:00,  1.05s/it]\n",
      " 64%|██████▎   | 700/1100 [2:20:26<1:14:49, 11.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_train-evaluator_pearson_cosine': 0.6941265754467635, 'eval_train-evaluator_spearman_cosine': 0.77256439298445, 'eval_train-evaluator_pearson_manhattan': 0.6674279804719248, 'eval_train-evaluator_spearman_manhattan': 0.7725158979916013, 'eval_train-evaluator_pearson_euclidean': 0.6696985162968796, 'eval_train-evaluator_spearman_euclidean': 0.7725620858783503, 'eval_train-evaluator_pearson_dot': 0.6941265935031556, 'eval_train-evaluator_spearman_dot': 0.772563760495404, 'eval_train-evaluator_pearson_max': 0.6941265935031556, 'eval_train-evaluator_spearman_max': 0.77256439298445, 'eval_runtime': 29.6088, 'eval_samples_per_second': 0.0, 'eval_steps_per_second': 0.0, 'epoch': 63.64}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 800/1100 [2:39:22<1:03:24, 12.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.4904, 'grad_norm': 59.78976821899414, 'learning_rate': 6.060606060606061e-06, 'epoch': 72.73}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 16/16 [00:12<00:00,  1.27it/s]\n",
      "Batches: 100%|██████████| 16/16 [00:17<00:00,  1.09s/it]\n",
      " 73%|███████▎  | 800/1100 [2:39:52<1:03:24, 12.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_train-evaluator_pearson_cosine': 0.6912692980546019, 'eval_train-evaluator_spearman_cosine': 0.779272009051356, 'eval_train-evaluator_pearson_manhattan': 0.6618673555257739, 'eval_train-evaluator_spearman_manhattan': 0.7780464992583549, 'eval_train-evaluator_pearson_euclidean': 0.6634079620704592, 'eval_train-evaluator_spearman_euclidean': 0.779269681914328, 'eval_train-evaluator_pearson_dot': 0.6912692868418887, 'eval_train-evaluator_spearman_dot': 0.779267199657811, 'eval_train-evaluator_pearson_max': 0.6912692980546019, 'eval_train-evaluator_spearman_max': 0.779272009051356, 'eval_runtime': 30.1735, 'eval_samples_per_second': 0.0, 'eval_steps_per_second': 0.0, 'epoch': 72.73}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 900/1100 [2:59:29<45:49, 13.75s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.362, 'grad_norm': 38.84254837036133, 'learning_rate': 4.04040404040404e-06, 'epoch': 81.82}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 16/16 [00:12<00:00,  1.24it/s]\n",
      "Batches: 100%|██████████| 16/16 [00:17<00:00,  1.09s/it]\n",
      " 82%|████████▏ | 900/1100 [2:59:59<45:49, 13.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_train-evaluator_pearson_cosine': 0.692645173001219, 'eval_train-evaluator_spearman_cosine': 0.7752767449165267, 'eval_train-evaluator_pearson_manhattan': 0.6616407193160773, 'eval_train-evaluator_spearman_manhattan': 0.7748340521006754, 'eval_train-evaluator_pearson_euclidean': 0.6629959255977005, 'eval_train-evaluator_spearman_euclidean': 0.7752744297105407, 'eval_train-evaluator_pearson_dot': 0.692645171433253, 'eval_train-evaluator_spearman_dot': 0.7752739510311966, 'eval_train-evaluator_pearson_max': 0.692645173001219, 'eval_train-evaluator_spearman_max': 0.7752767449165267, 'eval_runtime': 30.4977, 'eval_samples_per_second': 0.0, 'eval_steps_per_second': 0.0, 'epoch': 81.82}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 1000/1100 [3:18:58<18:05, 10.86s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.2524, 'grad_norm': 16.314697265625, 'learning_rate': 2.02020202020202e-06, 'epoch': 90.91}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 16/16 [00:11<00:00,  1.37it/s]\n",
      "Batches: 100%|██████████| 16/16 [00:15<00:00,  1.02it/s]\n",
      " 91%|█████████ | 1000/1100 [3:19:25<18:05, 10.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_train-evaluator_pearson_cosine': 0.6895443176920923, 'eval_train-evaluator_spearman_cosine': 0.7747806218238421, 'eval_train-evaluator_pearson_manhattan': 0.6579397980099163, 'eval_train-evaluator_spearman_manhattan': 0.7735869791584528, 'eval_train-evaluator_pearson_euclidean': 0.6587958282062126, 'eval_train-evaluator_spearman_euclidean': 0.7747783080994266, 'eval_train-evaluator_pearson_dot': 0.6895443400293891, 'eval_train-evaluator_spearman_dot': 0.7747799760982238, 'eval_train-evaluator_pearson_max': 0.6895443400293891, 'eval_train-evaluator_spearman_max': 0.7747806218238421, 'eval_runtime': 27.513, 'eval_samples_per_second': 0.0, 'eval_steps_per_second': 0.0, 'epoch': 90.91}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1100/1100 [3:38:02<00:00, 10.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1732, 'grad_norm': 2.187600612640381, 'learning_rate': 0.0, 'epoch': 100.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 16/16 [00:15<00:00,  1.02it/s]\n",
      "Batches: 100%|██████████| 16/16 [00:23<00:00,  1.46s/it]\n",
      "100%|██████████| 1100/1100 [3:38:42<00:00, 10.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_train-evaluator_pearson_cosine': 0.6899927880800748, 'eval_train-evaluator_spearman_cosine': 0.77506730611496, 'eval_train-evaluator_pearson_manhattan': 0.6575149776113081, 'eval_train-evaluator_spearman_manhattan': 0.7749200571311735, 'eval_train-evaluator_pearson_euclidean': 0.6583362837014505, 'eval_train-evaluator_spearman_euclidean': 0.7750649915344203, 'eval_train-evaluator_pearson_dot': 0.6899927847975237, 'eval_train-evaluator_spearman_dot': 0.7750636027960498, 'eval_train-evaluator_pearson_max': 0.6899927880800748, 'eval_train-evaluator_spearman_max': 0.77506730611496, 'eval_runtime': 39.2342, 'eval_samples_per_second': 0.0, 'eval_steps_per_second': 0.0, 'epoch': 100.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1100/1100 [3:38:49<00:00, 10.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 13129.7054, 'train_samples_per_second': 1.881, 'train_steps_per_second': 0.084, 'train_loss': 2.947750868363814, 'epoch': 100.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1100/1100 [3:38:50<00:00, 11.94s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1100, training_loss=2.947750868363814, metrics={'train_runtime': 13129.7054, 'train_samples_per_second': 1.881, 'train_steps_per_second': 0.084, 'total_flos': 0.0, 'train_loss': 2.947750868363814, 'epoch': 100.0})"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = SentenceTransformerTrainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=training_data,\n",
    "    # eval_dataset=eval_dataset,\n",
    "    loss=loss,\n",
    "    evaluator=dev_evaluator,\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"fine-tuned/models/chatPMB-pretrained-2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Tags by index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         gr_hi\n",
       "1         gr_ha\n",
       "2         gr_pa\n",
       "3         gr_si\n",
       "4         gr_so\n",
       "         ...   \n",
       "242    beasiswa\n",
       "243    beasiswa\n",
       "244    beasiswa\n",
       "245    beasiswa\n",
       "246    beasiswa\n",
       "Name: tag, Length: 247, dtype: object"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = pd.read_csv('data/dataset-question.csv')\n",
    "labels = labels.iloc[:-12]\n",
    "labels = labels['tag']\n",
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Usage of Pretrained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer(\"fine-tuned/models/chatPMB-pretrained-2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = model.encode(\"Saya sedang mencari informasi seputar biaya UKT di UIN Sunan Gunung Djati Bandung\")\n",
    "to_test = model.encode(df['sentence_2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(224,\n",
       " 'ukt',\n",
       " array([[-0.08102501, -0.09274451, -0.0194903 , -0.09801254, -0.07346375,\n",
       "          0.01122001, -0.04107093,  0.02444862,  0.00458639,  0.16658112,\n",
       "          0.376706  ,  0.2224128 ,  0.39654344,  0.12525932,  0.1698928 ,\n",
       "          0.33939266,  0.18692902,  0.42380178,  0.15407269, -0.02946443,\n",
       "          0.0310082 , -0.04368572,  0.10426041,  0.04318966,  0.11615118,\n",
       "          0.08738878,  0.00334094,  0.05256866,  0.0368742 ,  0.0036604 ,\n",
       "         -0.08304228, -0.1332272 , -0.13874346,  0.08654732,  0.2074686 ,\n",
       "          0.1313885 ,  0.44935143,  0.14125264,  0.2567071 ,  0.4249447 ,\n",
       "          0.18028516,  0.20853628,  0.37663478,  0.05177975,  0.14704998,\n",
       "          0.17423037,  0.21683279,  0.17834032,  0.02997787,  0.05023821,\n",
       "          0.12785752,  0.0825028 ,  0.04757181,  0.05177975,  0.14704998,\n",
       "          0.17423037,  0.21683279,  0.17834032,  0.02997787,  0.05023821,\n",
       "          0.12785752,  0.0825028 ,  0.04757181,  0.12470879,  0.08080865,\n",
       "          0.15623328,  0.08654497,  0.01852312,  0.08243643,  0.14973913,\n",
       "          0.10565022,  0.06008134,  0.12265211,  0.05829049, -0.0693645 ,\n",
       "         -0.2287988 , -0.14691108,  0.1366883 ,  0.07457735,  0.20292899,\n",
       "          0.18692271,  0.07626577,  0.07289511,  0.17381936,  0.17086342,\n",
       "          0.21608995,  0.10274833,  0.08132118, -0.02913237, -0.19295952,\n",
       "         -0.11406917,  0.15834743,  0.28385943,  0.1760237 ,  0.09222782,\n",
       "          0.07326768,  0.28028843,  0.13519245,  0.15249327,  0.13267109,\n",
       "          0.3145048 ,  0.14878696,  0.16148138,  0.16265783,  0.14058724,\n",
       "          0.14093089,  0.1523723 ,  0.23185205,  0.12727755,  0.22460872,\n",
       "          0.17837268,  0.04256015, -0.06451018,  0.03658549,  0.09815394,\n",
       "          0.103415  ,  0.09330168,  0.11908838,  0.11091462, -0.05258809,\n",
       "          0.06646625,  0.05691263, -0.06366122,  0.0973996 ,  0.1214679 ,\n",
       "          0.06917579,  0.08448671,  0.15073676,  0.04945219,  0.05454898,\n",
       "          0.1486676 ,  0.06003139,  0.09254624,  0.18886568,  0.05756306,\n",
       "         -0.18600103,  0.2739558 ,  0.22137368,  0.2621641 ,  0.03627436,\n",
       "          0.23853292,  0.12815782,  0.17755033,  0.21396345,  0.13441366,\n",
       "          0.26241258,  0.27588832,  0.26513994,  0.26746202,  0.20779116,\n",
       "          0.23248608,  0.19555296,  0.23153377,  0.27877286,  0.1544838 ,\n",
       "          0.27305537,  0.01870811,  0.10736966,  0.01441029,  0.28694856,\n",
       "          0.07512854,  0.07381974,  0.03235142,  0.0532625 ,  0.34964508,\n",
       "          0.09314504,  0.0140269 ,  0.03736607,  0.06947552,  0.21826148,\n",
       "          0.05677247,  0.12994638,  0.09257926,  0.07769464,  0.05398022,\n",
       "          0.07503402,  0.09163283,  0.06024893,  0.09941366,  0.07748453,\n",
       "          0.22786324,  0.14469707, -0.08640285,  0.0471769 ,  0.20380437,\n",
       "          0.34428573,  0.05254178,  0.02689309,  0.13538241,  0.13450345,\n",
       "          0.1396958 ,  0.19409601,  0.11858316, -0.00585932,  0.12794638,\n",
       "          0.05479797, -0.00620508, -0.05650925, -0.01397557,  0.03882051,\n",
       "         -0.18551639, -0.09569409,  0.01391279,  0.24382156, -0.10808399,\n",
       "          0.1930602 ,  0.03507768, -0.04719706,  0.00630797,  0.05570295,\n",
       "          0.07554552, -0.10391399, -0.12309295, -0.03533819,  0.09127684,\n",
       "         -0.146187  , -0.3141311 ,  0.0032581 ,  0.47047907,  0.59760773,\n",
       "          0.77919304,  0.51277757,  0.5246468 ,  0.72144103,  0.8090235 ,\n",
       "          0.70866454,  0.5945351 ,  0.78793305,  0.55165946,  0.4984965 ,\n",
       "          0.5012948 ,  0.5743553 ,  0.51923966,  0.5143317 ,  0.5258484 ,\n",
       "          0.56651914,  0.505816  ,  0.49768618,  0.45509982,  0.09963231,\n",
       "          0.3124596 ,  0.3942671 ,  0.28177387,  0.12157939,  0.11686511,\n",
       "          0.34965312,  0.07164243]], dtype=float32))"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = np.array(model.similarity(sentence, to_test))\n",
    "index = np.argmax(result)\n",
    "detected_label = labels[index]\n",
    "index, detected_label, result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
